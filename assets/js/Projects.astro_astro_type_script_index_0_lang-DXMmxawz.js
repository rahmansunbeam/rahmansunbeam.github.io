const g={projects:[{image:"/images/project_1_rahmansunbeam.png",name:"LiDAR data processing for Canopy Height Model (CHM)",description:"In this project Remotely Piloted Aircraft System (RPAS) point cloud data was processed to identify the CHM using LasTools and ArcGIS Pro. The LasClassify tool was instrumental         in classifying vegetation point clouds from the surrounding classes.",fullDescription:"In this project Remotely Piloted Aircraft System (RPAS) point cloud data was processed to identify the CHM using LasTools and ArcGIS Pro. The LasClassify tool was instrumental         in classifying vegetation point clouds from the surrounding classes. The Digital Surface Model (DSM) and Digital Terrain Model (DTM) were also processed to validate the output.",dataAndTools:["Processed over 30GB of LiDAR point cloud data","Reduced processing time by 40% using LasTools CLI interface","Used ArcGIS Pro for validating the output"],gallery:["/images/project_1_1_rahmansunbeam.png"],methodology:"The project utilized advanced point cloud classification algorithms, including ground filtering, vegetation detection, and height model generation. The image was       subdivided into tiles for faster processing and ensure consistent results across multiple datasets.",results:"The main challenge was handling the large volume of LiDAR data while maintaining processing speed and accuracy. Dense vegetation areas required specialized filtering       techniques to separate canopy from ground points effectively.",skills:["LasTools","Python","ArcGIS Pro"],link:""},{image:"/images/project_2_rahmansunbeam.png",name:"Comparing BEV Charging Costs in Calgary and Montréal Island: A Network Analyst-based model for estimating per-kilometer travel costs",description:"This was a comparative analysis using a Network Analyst-based model to estimate per-kilometer travel costs for Battery Electric Vehicles (BEVs). The study used Level-2 and         Level-3 charging station data to calculate costs in Calgary and Montréal Island.",fullDescription:"This was a comparative analysis using a Network Analyst-based model to estimate per-kilometer travel costs for Battery Electric Vehicles (BEVs). The study used Level-2 and         Level-3 charging station data to calculate costs in Calgary and Montréal Island. Results suggested that Calgary pays much higher than Montréal Island for BEV charging. This         Story Map was developed as part of a GEOG588 term project in March, 2025 for the University of Calgary.",dataAndTools:["L2 and L3 charging station locations obtained from Natural Resources Canada","Road network layer; transport node point locations i.e. bus stops; polygons representing transport areas i.e. airports collected from Open Street Map","Digital Elevation Model (DEM) data from the HRDEM project"],gallery:["/images/project_2_1_rahmansunbeam.jpg","/images/project_2_2_rahmansunbeam.png","/images/project_2_3_rahmansunbeam.png","/images/project_2_4_rahmansunbeam.png"],methodology:"The project utilized a Network Analyst-based model and a Python-based 'cost function' to analyze comparable routes in the two cities. The model estimated per-kilometer travel       costs for BEVs by considering charging station location proximity, road network distance, and elevation data. A sensitivity analysis was also performed.",results:"The results showed that Calgary has a significantly lower number of stations (0.336 stations/km²) compared to Montreal Island (1.94 stations/km²). This, along with the higher       slopes on many of its roads, contributed to increased travel costs for BEVs in Calgary. Calgary was on average 2.6% more expensive than Montreal along the shortest route. Moreover,       both cities roughly pay $5 for BEV charging per kilometer to travel a similar distance, while gas costs around $2.",skills:["Network Analysis","Story Map","ArcGIS Pro","Python","MGIS Project"],link:"https://storymaps.arcgis.com/stories/d2e050d3403c47aa870f87d354574c8c"},{image:"/images/project_3_rahmansunbeam.png",name:"Solar Radiation Toolset of ArcGIS Pro: A demonstration using LiDAR data",description:"The Solar Radiation toolset in ArcGIS Pro helps to analyze the effects of the sun over a geographic area for specific time periods. This toolset is designed to analyze and         model solar radiation, which is crucial for various applications such as solar energy planning, site suitability analysis, and environmental assessment.",fullDescription:"The Solar Radiation toolset in ArcGIS Pro helps to analyze the effects of the sun over a geographic area for specific time periods. This toolset is designed to analyze and         model solar radiation, which is crucial for various applications such as solar energy planning, site suitability analysis, and environmental assessment. The objectives of this         project were to use the Raster Solar Radiation tool to calculate the photovoltaic potential of an area in Prince George, BC and to demonstrate other tools of the toolset.         This Story Map was produced for the final term project of GEOG647, MGIS course, Winter 2024 semester, University of Calgary.",dataAndTools:["Digital Surface Model produced from Point Cloud data collected from the LidarBC web portal. The spatial resolution was 0.25m, NAD83(CSRS) / UTM 10N projection","Open building footprints from Microsoft GitHub in shapefile; a total of 4,347 buildings were found in the study area","Raster Solar Radiation tool in ArcGIS Pro"],gallery:["/images/project_3_1_rahmansunbeam.png","/images/project_3_2_rahmansunbeam.png"],methodology:"The project started by masking out the buildings from the DSM to focus on the rooftops. The Raster Solar Radiation tool was then applied to calculate the amount of solar       radiation energy received per unit area during the year 2023 in kWh/m². After further adjusting the raster, a Zonal Statistics tool was used to summarize the solar radiation values       for each building footprint.",results:"The final PV potential map shows that there are a few buildings in Prince George that could have produced up to 1,645 MWh/m² of electricity in 2023 if they had installed solar       panels.",skills:["LiDAR","ArcGIS Pro","Story Map","MGIS Project"],link:"https://storymaps.arcgis.com/stories/c327b238231a4bd2bdb549373d2c67aa"},{image:"/images/project_4_rahmansunbeam.png",name:"Ord’s Kangaroo Rat: A ModelBuilder toolset for habitat suitability analysis of an endangered rodent in the arid landscape of southern Alberta",description:"Ord’s Kangaroo Rat (<i>Dipodomys ordii</i>) is a fascinating rodent found in the arid landscape of Alberta, Canada. This story map explores the habitats of this endangered species         using GIS-based modeling techniques.",fullDescription:"Ord’s Kangaroo Rat (<i>Dipodomys ordii</i>) is a fascinating rodent found in the arid landscape of Alberta, Canada. This story map explores the habitats of this endangered species         using GIS-based modeling techniques. The objective of this assignment was to identify the suitable habitat locations of Ord's Kangaroo Rats. The study area was in the Middle         Sand Hills region north of Medicine Hat. ArcGIS Pro's ModelBuilder and Python interface was used to process Digital Elevation Models (DEMs), terrain information and road data         to analyze the landscape and identify potential habitat zones. This Story Map was produced for the GEOG647, MGIS course, Winter 2024 semester, University of Calgary.",dataAndTools:["25m resolution Digital Elevation Model (DEM) data","Road layer with surface type information","Polygon layer of active dune areas, CFB Suffield boundary, ecological range classes, Kangaroo Rat sighting locations etc.","ModelBuilder and Python interface in ArcGIS Pro"],gallery:["/images/project_4_1_rahmansunbeam.png","/images/project_4_2_rahmansunbeam.png"],methodology:"The ModelBuilder toolset was used to process the DEM data, road layer, and polygon layers to identify suitable habitats. After the initial processing, a Weighted Overlay       analysis was performed to combine various factors influencing habitat suitability, such as elevation, slope, proximity to roads, and ecological range.",results:"The overall result shows that the resultant habitats are mostly in the eastern and southeastern part of the study area, where most of the observations are found. The northeastern       part is found to be the most suitable location for the rodent habitat.",skills:["ModelBuilder","ArcGIS Pro","Story Map","MGIS Project"],link:"https://storymaps.arcgis.com/stories/84a6fe88298a4f4c98364635ed6e8cc4"},{image:"/images/project_5_rahmansunbeam.png",name:"Visualization tool for historical climate trend of various land cover classes using Google Earth Engine (GEE)",description:"This project used GEE to visualize historical climate trends across different land cover classes using WorldCover and CMIP6 climate data. Inside this GEE app, when the user         clicked on a point on the map, it would show the historical climate data for that location differentiated by land cover classes.",fullDescription:"This project used GEE to visualize historical climate trends across different land cover classes using WorldCover and CMIP6 climate data. Inside this GEE app, when the user         clicks on a point on the map, it generates a historical temperature trend of a 10-kilometer buffer area differentiated by land cover classes using 'zonal statistics'. The results         showed striking geographical features like urban heat islands, land cover-wise temperature trends among different continents, and the impact of land cover on climate. This project         was developed as part of a GEOG633 term project in Winter, 2024 for the University of Calgary.",dataAndTools:["Coupled Model Intercomparison Project Phase 6 (CMIP6) CanESM5 data for historical temperature (1990-2023) at 0.25° resolution","WorldCover data by the European Space Agency (ESA) which has 11 landcover classes at 10m resolution","GEE online editor"],gallery:["/images/project_5_1_rahmansunbeam.png","/images/project_5_2_rahmansunbeam.png","/images/project_5_3_rahmansunbeam.png","/images/project_5_4_rahmansunbeam.png"],methodology:"The datasets were obtained from the GEE data catalog. The CMIP6 data was filtered for the historical period (1990-2023) and the WorldCover data was used to classify the land cover types.       Zonal statistics calculated the mean temperature for each land cover class within a 10-kilometer buffer around a clicked point. The results were visualized using       GEE's charting capabilities.",results:"The results showed a number of interesting patterns. Urban areas exhibited higher temperature trends compared to surrounding rural areas, indicating the presence of urban heat islands.       For example, Beijing showed a significantly higher temperature trend in urban areas compared to its surroundings.",skills:["Google Earth Engine","Climate trend","JavaScript","MGIS Project"],link:"https://github.com/rahmansunbeam/geog633_proj_climatetrend"},{image:"/images/project_6_rahmansunbeam.png",name:"Vegetation analysis with hyperspectral data and OBIA",description:"This was an analysis using 0.1m hyperspectral RPAS images (visible and infrared bands) to detect and analyze Ash trees. The forest vegetation was highly dense, so GLCM texture         analysis in ENVI was used.",fullDescription:"This was an analysis using 0.1m hyperspectral RPAS images (visible and infrared bands) to detect and analyze the health of Ash trees. The forest vegetation was highly dense, so GLCM texture         analysis in ENVI and OBIA classification in eCognition helped to identify Ash trees. The study area was in Halstone, United Kingdom. The results were validated with field data and provided         insights into the health and distribution of Ash trees in the area. This output was produced for a Fiverr client in 2024.",dataAndTools:["0.1m hyperspectral imagery with 200 spectral bands","ENVI, ArcGIS Pro's Python interface, and eCognition Developer were used."],gallery:["/images/project_6_1_rahmansunbeam.png"],methodology:"First, a Python script was used to reduce the dimensionality of the hyperspectral data into five bands - red, green, blue, NIR, and SWIR. The Grey-level co-occurrence matrix (GLCM)       texture analysis in ENVI was used to extract texture features from the hyperspectral imagery to identify additional bands. ArcGIS Pro was also used to calculate vegetation indices (e.g., NDVI, SAVI, etc.).       Finally, after stacking all bands, a multiresolution segmentation in eCognition was applied to the imagery.",results:"The results were promising, showing the potential of hyperspectral imagery and advanced processing techniques in vegetation analysis. The overall accuracy was over 85%.",skills:["ENVI","eCognition","Python","ArcGIS Pro"],link:""},{image:"/images/project_7_rahmansunbeam.png",name:"Canopy crown identification using LiDAR data and OBIA",description:"Identification of tree crowns using LiDAR data can be easily achieved with remote sensing software like LasTools and eCognition. LasTools is designed to process large and         complex LiDAR RPAS datasets into a Canopy Height Model (CHM) efficiently. In this project, LASGround was used to refine the canopy coverage in challenging terrain areas.",fullDescription:"Identification of tree crowns using LiDAR data can be easily achieved with remote sensing software like LasTools and eCognition. LasTools is designed to process large and         complex LiDAR RPAS datasets into a Canopy Height Model (CHM) efficiently. In this project, LASGround was used to refine the canopy coverage in challenging terrain areas.         Next, multiresolution segmentation in eCognition Developer was applied to the CHM to produce distinctly identifiable concentric objects, particularly characterized as         tree crowns. The final output was cleaned and mapped using ArcGIS Pro software. This output was produced for a Fiverr client in 2024.",dataAndTools:["Point cloud data of Halstone, UK","LasTools, ArcGIS Pro, and eCognition Developer were used."],gallery:["/images/project_7_1_rahmansunbeam.png"],methodology:"LasTools were used to create tiles and identify the CHM from the point cloud data. Next, the CHM was imported into eCognition Developer, where multiresolution segmentation       was applied. In the process tree, distinctive features were filtered out, such as 'elliptical fit' <= 1.5, 'maximum object size' >= 500px, and 'brightness' >= 50. The final output was exported       as a shapefile and cleaned in ArcGIS Pro.",results:"The results were promising, showing the potential of LiDAR data and OBIA techniques in vegetation analysis. The accuracy was not calculated due to the lack of field data for validation.",skills:["LasTools","eCognition","ArcGIS Pro"],link:""}]},d=document.getElementById("load-more-btn"),s=document.querySelectorAll(".project-item"),i=document.getElementById("project-modal"),c=document.getElementById("modal-content"),p=document.getElementById("close-modal");let n=5;const m=t=>{const e=document.createElement("div");e.className="fixed inset-0 bg-black bg-opacity-90 z-[60] flex items-center justify-center p-4",e.innerHTML=`
    <div class="relative max-w-6xl max-h-full">
      <button class="absolute top-4 right-4 w-8 h-8 flex items-center justify-center bg-gray-100 rounded-full hover:bg-gray-200 transition-colors" onclick="this.closest('.fixed').remove()">
        <svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
          <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12" />
        </svg>
      </button>
      <img src="${t}" alt="Project Image" class="max-w-full max-h-full object-contain rounded-lg" />
    </div>
  `,e.addEventListener("click",a=>{a.target===e&&e.remove()}),document.body.appendChild(e)};d&&s.length>5&&d.addEventListener("click",()=>{const t=s.length-n,e=Math.min(t,5);for(let a=n;a<n+e;a++)s[a]&&(s[a].classList.remove("hidden"),s[a].classList.add("animate-fade-in"));n+=e,n>=s.length&&(d.style.display="none")});const h=t=>{if(!i||!c)return;const e=g.projects[t];if(!e)return;const a=e.link&&e.link.trim()!=="";c.innerHTML=`
    <div class="space-y-6">
      ${e.image?`
        <div class="rounded-lg overflow-hidden">
          <img src="${e.image}" alt="${e.name}" class="w-full h-64 sm:h-80 object-cover" />
        </div>
      `:""}
      
      <div>
        <h3 class="text-2xl sm:text-3xl font-bold text-gray-900 mb-4">${e.name}</h3>
        <p class="text-lg text-black leading-relaxed mb-6">${e.fullDescription}</p>
        
        <div class="bg-teal-50 rounded-lg p-6 mb-6">
          ${e.dataAndTools?.length>0?`
            <div class="mb-6">
              <h4 class="text-xl font-semibold text-gray-900 mb-3">Data and tools</h4>
              <ul class="space-y-2">
                ${e.dataAndTools.map(o=>`
                  <li class="flex items-start gap-3">
                    <svg class="w-5 h-5 text-green-600 mt-0.5 flex-shrink-0" fill="currentColor" viewBox="0 0 20 20">
                      <path fill-rule="evenodd" d="M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z" clip-rule="evenodd"/>
                    </svg>
                    <span class="text-gray-700">${o}</span>
                  </li>
                `).join("")}
              </ul>
            </div>
          `:""}
          
          ${e.gallery?.length>0?`
            <div class="mb-6">
              <h4 class="text-xl font-semibold text-gray-900 mb-3">Project gallery</h4>
              <div class="${e.gallery.length===1?"grid grid-cols-1 gap-4":"grid grid-cols-1 sm:grid-cols-2 gap-4"}" id="gallery-${t}">
                ${e.gallery.map((o,r)=>`
                  <div class="rounded-lg overflow-hidden cursor-pointer hover:shadow-lg transition-shadow duration-300 gallery-image" data-image-src="${o}">
                    <img src="${o}" alt="${e.name} - Image ${r+1}" class="w-full ${e.gallery.length===1?"h-auto":"h-48"} object-cover hover:scale-105 transition-transform duration-300" />
                  </div>
                `).join("")}
              </div>
            </div>
          `:""}
          
          ${e.methodology?`
            <div class="mb-6">
              <h4 class="text-xl font-semibold text-gray-900 mb-3">Method</h4>
              <p class="text-base text-gray-700 leading-relaxed">${e.methodology}</p>
            </div>
          `:""}
          
          ${e.results?`
            <div class="${e.methodology?"mb-0":"mb-6"}">
              <h4 class="text-xl font-semibold text-gray-900 mb-3">Results</h4>
              <p class="text-base text-gray-700 leading-relaxed">${e.results}</p>
            </div>
          `:""}
        </div>
        
        <div class="flex flex-wrap gap-2 mb-6">
          ${e.skills?.map(o=>`<span class="px-3 py-1.5 bg-gray-900 text-white rounded-lg text-sm font-medium">${o}</span>`).join("")||""}
        </div>
        
        ${a?`
          <div class="pt-4">
            <a 
              href="${e.link}" 
              target="_blank" 
              rel="noopener noreferrer"
              class="inline-flex items-center gap-2 px-6 py-3 bg-gray-900 text-white rounded-lg font-medium transition-all duration-300 hover:bg-gray-700 hover:shadow-lg"
            >
              <span>View project</span>
              <svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14" />
              </svg>
            </a>
          </div>
        `:""}
      </div>
    </div>
  `,i.classList.remove("hidden"),document.body.style.overflow="hidden",c.querySelectorAll(".gallery-image").forEach(o=>{o.addEventListener("click",()=>{const r=o.getAttribute("data-image-src");r&&m(r)})})};s.forEach((t,e)=>{const a=t.querySelector(".project-title"),l=t.querySelector(".project-button");a&&a.addEventListener("click",()=>h(e)),l&&l.addEventListener("click",()=>h(e))});p?.addEventListener("click",()=>{i?.classList.add("hidden"),document.body.style.overflow="auto"});i?.addEventListener("click",t=>{t.target===i&&(i.classList.add("hidden"),document.body.style.overflow="auto")});
